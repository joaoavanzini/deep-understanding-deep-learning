{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bhWV8oes-wKR"
      },
      "source": [
        "# COURSE: A deep understanding of deep learning\n",
        "## SECTION: Math prerequisites\n",
        "### LECTURE: Matrix multiplication\n",
        "#### TEACHER: Mike X Cohen, sincxpress.com\n",
        "##### STUDENT: Jo√£o Avanzini\n",
        "###### COURSE URL: udemy.com/course/deeplearning_x/?couponCode=202305"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vRQNyNtlDoOb"
      },
      "source": [
        "# import libraries\n",
        "import numpy as np\n",
        "import torch"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K0BSQG0fDpt_"
      },
      "source": [
        "# Using numpy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4_veEYqDpx9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "711e9fa3-0a06-42f5-c215-3265172c45e4"
      },
      "source": [
        "# create some random matrices\n",
        "A = np.random.randn(3,4)\n",
        "B = np.random.randn(4,5)\n",
        "C = np.random.randn(3,7)\n",
        "\n",
        "# try some multiplications...\n",
        "print(np.round( A@B   ,2)), print(' ')\n",
        "# print(np.round( A@C   ,2)), print(' ')\n",
        "# print(np.round( B@C   ,2)), print(' ')\n",
        "print(np.round( C.T@A ,2))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-0.37  3.03  1.67 -0.73 -6.  ]\n",
            " [ 0.35  1.89  0.87 -1.12  3.98]\n",
            " [-0.5  -1.9   1.49  0.75 -1.04]]\n",
            " \n",
            "[[ 0.76  1.82 -0.31 -0.32]\n",
            " [-1.9   2.27 -0.17 -1.46]\n",
            " [ 2.96 -1.31  0.09 -0.05]\n",
            " [-7.53 -1.55  0.8  -2.37]\n",
            " [-1.31  1.62 -0.09 -1.38]\n",
            " [ 2.69  2.21 -0.69  2.38]\n",
            " [ 2.97 -1.4  -0.07  1.99]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89qsNy19Dp1U"
      },
      "source": [
        "# Using pytorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Yrdf4WOEjxz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05eb72e2-65b0-4db1-a3d9-8fc3bb6dd8dd"
      },
      "source": [
        "# create some random matrices\n",
        "A  = torch.randn(3,4)\n",
        "B  = torch.randn(4,5)\n",
        "C1 = np.random.randn(4,7)\n",
        "C2 = torch.tensor( C1,dtype=torch.float )\n",
        "\n",
        "# try some multiplications...\n",
        "# print(np.round( A@B   ,2)), print(' ')\n",
        "# print(np.round( A@B.T ,2)), print(' ')\n",
        "print(np.round( A@C1  ,2)), print(' ')\n",
        "print(np.round( A@C2  ,2))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.3800, -3.1300,  0.5100,  0.4000, -0.8000,  0.9300, -0.8000],\n",
            "        [ 1.3200, -2.8400, -0.2900,  0.9300, -1.1900, -0.2400,  1.3400],\n",
            "        [ 0.1600,  0.1600, -0.1200, -0.3500,  1.2200, -1.8700,  1.7900]],\n",
            "       dtype=torch.float64)\n",
            " \n",
            "tensor([[ 0.3800, -3.1300,  0.5100,  0.4000, -0.8000,  0.9300, -0.8000],\n",
            "        [ 1.3200, -2.8400, -0.2900,  0.9300, -1.1900, -0.2400,  1.3400],\n",
            "        [ 0.1600,  0.1600, -0.1200, -0.3500,  1.2200, -1.8700,  1.7900]])\n"
          ]
        }
      ]
    }
  ]
}